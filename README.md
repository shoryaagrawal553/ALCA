# ğŸ“˜ ALCA â€” Adaptive Learning Companion Agent

## ğŸ“‘ Table of Contents

1. [Features Overview](#-features-overview)
2. [System Architecture](#-system-architecture)
3. [Project Structure](#-project-structure)
4. [Getting Started](#-getting-started)
5. [Using ALCA](#-using-alca)
   - [Get Topics](#-1-get-topics)
   - [Request a Question](#-2-request-a-question)
   - [Submit an Answer](#-3-submit-an-answer)
   - [Get Memory](#-4-get-memory)
   - [Session Management](#-5-session-management)
   - [Run Evaluator](#-6-run-evaluator-judging-tool)
6. [CLI Demo](#-cli-demo-user-mode)
7. [Observability & Logging](#-observability--logging)
8. [How It Works Internally](#-how-it-works-internally-high-level)
9. [2â€‘Minute Demo Script](#-2-minute-demo-script-for-judges)
10. [Project Badges](#-project-badges-visual-polish)
11. [Why ALCA Is Competition-Ready](#-why-alca-is-competition-ready)
12. [License](#-license)
13. [Final Notes](#-alca-is-ready-for-submission)



*A Multi-Agent, Tool-Based, Memory-Driven Learning System*

ALCA is an adaptive learning platform built using **multi-agent architecture**, **custom tools**, **memory with SQLite**, **observability/logging**, **evaluation pipeline**, and a **REST API + CLI interface**.

It dynamically diagnoses learner knowledge, explains concepts at the right difficulty level, gives adaptive practice questions, evaluates answers, and tracks long-term progress.

---

# ğŸš€ Features Overview

| Capability             | Description                                                                            |
| ---------------------- | -------------------------------------------------------------------------------------- |
| **Multi-Agent System** | Diagnostic, Explanation, Practice, and Feedback agents coordinated by an orchestrator. |
| **Tools**              | Code execution, simple search, dataset-driven evaluation tools.                        |
| **Memory & Sessions**  | SQLite-based memory manager + session storage in JSONL format.                         |
| **Observability**      | Rotating logs for app, API, agents, evaluator; timing logs for every endpoint.         |
| **Evaluator**          | Automated evaluation across all topics (latency, scoring, practice accuracy).          |
| **APIs**               | /api/learn, /api/topics, /api/memory, /api/session, /api/evaluate                      |
| **CLI Demo**           | Fully interactive terminal experience for end-users.                                   |

---

# ğŸ§  System Architecture

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚          ALCA System           â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                        â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Diagnostics  â”‚        â”‚ Explanation   â”‚      â”‚ Practice Agent  â”‚
â”‚   Agent      â”‚        â”‚   Agent       â”‚      â”‚ (Adaptive Qs)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      (topic + difficulty)
                                â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Feedback   â”‚
                         â”‚   Agent    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                         Updates Memory
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  MemoryManager.db   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   Orchestrator    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     REST API / CLI Interface    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“‚ Project Structure

```
ALCA/
â”‚
â”œâ”€â”€ main.py                     # Flask API + Logging + Sessions
â”œâ”€â”€ agents.py                   # Multi-agent system
â”œâ”€â”€ memory.py                   # SQLite memory manager
â”œâ”€â”€ tools.py                    # Tools: code executor, search
â”œâ”€â”€ evaluator.py                # Auto evaluator
â”œâ”€â”€ demo_cli.py                 # Interactive CLI for users
â”‚
â”œâ”€â”€ sample_content_expanded.json
â”œâ”€â”€ sample_content.json
â”‚
â”œâ”€â”€ logs/                       # Observability logs (auto-generated)
â”‚   â”œâ”€â”€ app.log
â”‚   â”œâ”€â”€ agents.log
â”‚   â”œâ”€â”€ api_learn.log
â”‚   â”œâ”€â”€ api_memory.log
â”‚   â”œâ”€â”€ api_evaluate.log
â”‚   â””â”€â”€ evaluator.log
â”‚
â”œâ”€â”€ sessions/                   # Persistent user sessions
â”‚
â””â”€â”€ requirements.txt
```

---

# ğŸƒ Getting Started

## 1. Install dependencies

```
pip install -r requirements.txt
```

## 2. Run the server

```
python main.py
```

Server starts at:

```
http://127.0.0.1:8000
```

---

# ğŸ–¥ Using ALCA

## âœ” 1. Get Topics

```
GET /api/topics
```

Example output:

```json
{
    "topics": [
        {"name": "stacks", "has_explanations": true, "has_practice": true},
        {"name": "queues", "has_explanations": true, "has_practice": true}
    ]
}
```

---

## âœ” 2. Request a Question

```
POST /api/learn
{
  "user_id": "u1",
  "topic": "stacks",
  "answer": ""
}
```

---

## âœ” 3. Submit an Answer

```
POST /api/learn
{
  "user_id": "u1",
  "topic": "stacks",
  "answer": "LIFO"
}
```

Returns:

- correctness
- explanation
- difficulty level
- updated stats

---

## âœ” 4. Get Memory

```
GET /api/memory/u1
```

---

## âœ” 5. Session Management

### Store session:

```
POST /api/session/store
{"user_id":"u1", "payload":{"last_topic":"stacks"}}
```

### Retrieve session:

```
GET /api/session/u1
```

---

## âœ” 6. Run Evaluator (Judging Tool)

```
python evaluator.py sample_content_expanded.json
```

Produces:

```
evaluation_report.json
```

Includes:

- topic latency
- average correctness
- accuracy trends
- question counts

---

# ğŸ§ª CLI Demo (User Mode)

```
python demo_cli.py
```

Provides:

- topic list
- diagnostic
- explanation
- practice
- grading
- summary

This is the preferred mode for human users.

---

# ğŸ“Š Observability & Logging

All logs stored in `logs/`:

- app.log â€” server start, API loading
- agents.log â€” every agent call
- api\_learn.log â€” learning requests
- api\_memory.log â€” memory requests
- api\_evaluate.log â€” evaluator requests
- evaluator.log â€” metrics & scoring

Each request includes:

- timestamp
- agent invoked
- user\_id
- topic
- latency (ms)

---

# ğŸ§© Requirement-to-Feature Mapping

ALCA directly satisfies **all required capstone concepts**:

âœ” Multi-Agent System\
âœ” Orchestrator\
âœ” Custom Tools\
âœ” Sessions & Memory\
âœ” Observability (Logging + Timing)\
âœ” Evaluation Pipeline\
âœ” Dataset Integration\
âœ” Clean APIs + CLI Demo\
âœ” Fully Modular Architecture

All features are lightweight, clean, and professionally structured.

---

# ğŸ“„ License

MIT License

---

# ğŸ§© How It Works Internally (High-Level)

ALCA operates through a clean, modular execution pipeline:

1. **User Request** â†’ `/api/learn` or CLI input
2. **Orchestrator Activated** â†’ Chooses which agent to run (diagnostic, explanation, practice, feedback)
3. **Agent Processing** â†’ Generates question, explanation, or grades answer
4. **MemoryManager Update** â†’ Stores attempts, correctness, and history in SQLite
5. **Session Logging** â†’ Saves lightweight JSON session snapshot
6. **Observability Layer** â†’ Logs API timing, agent calls, evaluator output
7. **Response Sent** â†’ Adaptive explanation + stats returned to user

This modular pipeline ensures the system is:

- **Stable** (each module isolated)
- **Explainable** (logs + clear agent roles)
- **Adaptive** (difficulty based on user accuracy)
- **Extensible** (easy to add new agents/tools)

---

# ğŸš€ Quick Demonstration Guide

Use this script during your evaluation presentation:

### **1ï¸âƒ£ Start ALCA**

```bash
python main.py
```

Say: *"The ALCA backend is now running with full logging and observability."*

### **2ï¸âƒ£ Run the CLI Demo**

```bash
python demo_cli.py
```

Say:

- *"ALCA begins by diagnosing your understanding."*
- *"It then provides explanations based on difficulty."*
- *"Finally, it gives adaptive practice and updates memory automatically."*

### **3ï¸âƒ£ Show Memory Dashboard**

Open:

```
http://127.0.0.1:8000/api/memory/u1
```

Say: *"ALCA tracks accuracy, attempts, and history per topic using SQLite."*

### **4ï¸âƒ£ Show Logs**

Open the `/logs` folder. Say: *"ALCA logs every agent call, API request, evaluator run, and performance metric."*

### **5ï¸âƒ£ Run the Evaluator**

```bash
python evaluator.py sample_content_expanded.json
```

Say: *"The evaluator runs multi-topic analysis for latency, scoring, and correctness."*

### **6ï¸âƒ£ End With Topics API**

```
http://127.0.0.1:8000/api/topics
```

Say: *"All topics and capabilities are cleanly exposed via REST APIs."*

---

# ğŸ·ï¸ Project Badges (Visual Polish)

Add these badges at the top of the README for a professional look:

```
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Flask](https://img.shields.io/badge/Framework-Flask-green)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)
![Agents](https://img.shields.io/badge/AI-Multi--Agent-orange)
```

---

# ğŸ‰ ALCA is Ready for Submission

You now have a fully functional, clean, production-grade capstone project.

